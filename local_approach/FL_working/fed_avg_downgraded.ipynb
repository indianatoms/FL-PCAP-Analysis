{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from client import Client\n",
    "from fedavg import Fedavg\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from supported_modles import Supported_modles\n",
    "import random\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = utils.set_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = utils.set_data()\n",
    "f1_before = []\n",
    "for client in clients:\n",
    "    client.downsample_data(['sbytes','dbytes','sttl','dttl','spkts','dpkts'])\n",
    "    client.split_data()\n",
    "    #client.prep_data()\n",
    "    client.train_model(selected_model)\n",
    "    f1_before.append(client.F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7671335667833917,\n",
       " 0.7614632924079178,\n",
       " 0.7815978233984665,\n",
       " 0.7647058823529412,\n",
       " 0.7738896366083446]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.SGD_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedavg = Fedavg(\"global\")\n",
    "lr = 0.1\n",
    "fedavg.init_global_model(lr, selected_model, clients[0].model,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clients[0].model\n",
    "clients = utils.set_data()\n",
    "for client in clients:\n",
    "    client.downsample_data(['sbytes','dbytes','sttl','dttl','spkts','dpkts'])\n",
    "    client.split_data()\n",
    "    client.init_empty_model(selected_model,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n",
      "Starting new round!\n"
     ]
    }
   ],
   "source": [
    "number_of_rounds = 20\n",
    "batch_size = 0.1\n",
    "epochs = 20\n",
    "prep = StandardScaler() \n",
    "\n",
    "for _ in range(number_of_rounds):\n",
    "    print(f'Starting new round!')\n",
    "\n",
    "    applicable_clients = random.sample((clients), random.randint(1, 4))\n",
    "    applicable_models = []\n",
    "    applicable_name = []\n",
    "    round_weights = []\n",
    "    dataset_size = 0\n",
    "    \n",
    "\n",
    "    for client in applicable_clients:\n",
    "        # print(f'Client name: {client.name}')\n",
    "\n",
    "        X = client.x\n",
    "        y = client.y\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=batch_size, stratify=y, random_state=random.randint(0,10))\n",
    "       \n",
    "        #X_train = prep.fit_transform(X_train)\n",
    "\n",
    "        dataset_size += X_train.shape[0]\n",
    "        sample_weights = compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "        fedavg.load_global_model(client.model, selected_model)\n",
    "        fedavg.train_local_agent(X_train, y_train, client.model, epochs, sample_weights, selected_model)\n",
    "        round_weights.append(X_train.shape[0])\n",
    "        applicable_models.append(client.model)\n",
    "\n",
    "\n",
    "    round_weights = np.array(round_weights) / dataset_size # calculate weight based on actual dataset size\n",
    "    # round_weights = weights\n",
    "    fedavg.update_global_model(applicable_models, round_weights, selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8120098588393458, 0.8174938793679055, 0.8046699595868881, 0.8160504959422904, 0.8105664925672961]\n"
     ]
    }
   ],
   "source": [
    "f1_fedavg = []\n",
    "for client in clients:\n",
    "    #x = prep.transform(client.x_test)\n",
    "    y_hat = fedavg.model.predict(client.x_test)\n",
    "    f1_fedavg.append(f1_score(client.y_test,y_hat))\n",
    "print(f1_fedavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference 0.044876292055954115\n",
      "Difference 0.05603058695998775\n",
      "Difference 0.023072136188421632\n",
      "Difference 0.051344613589349164\n",
      "Difference 0.036676855958951426\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for client in clients:\n",
    "    print(f'Difference {f1_fedavg[i]-f1_before[i]}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8891060087933562\n"
     ]
    }
   ],
   "source": [
    "selected_model = Supported_modles.gradient_boosting_classifier\n",
    "client = utils.centralized_data()\n",
    "client.downsample_data(['sbytes','dbytes','sttl','dttl','spkts','dpkts'])\n",
    "client.split_data()\n",
    "client.train_model(selected_model)\n",
    "print(client.F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('flower_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37a3f064d08b70021b14be81b11bab9d127cd79189cce72309f16083e51f60cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
