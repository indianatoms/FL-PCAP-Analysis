{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('fede'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from client import Client\n",
    "import pandas as pd\n",
    "from supported_modles import Supported_modles\n",
    "import utils\n",
    "from fedavg import Fedavg\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node1.\n",
      "Creating node2.\n",
      "Creating node3.\n",
      "Creating node4.\n",
      "Creating node5.\n"
     ]
    }
   ],
   "source": [
    "clients, test_x, test_y = utils.set_data(False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.MLP_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4360285063990149\n",
      "0.49486969944610915\n"
     ]
    }
   ],
   "source": [
    "f1_before = []\n",
    "for client in clients:\n",
    "    client.init_empty_model(selected_model,0.01)\n",
    "    client.train_model()\n",
    "    # score = client.test_model_f1()\n",
    "    y_hat = client.model.predict(test_x)\n",
    "    score = f1_score(test_y,y_hat, average=\"binary\")\n",
    "    f1_before.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 98] Address already in use\n",
      "Waitiing for a Connection..\n"
     ]
    }
   ],
   "source": [
    "fedavg = Fedavg(\"global\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in clients:\n",
    "    client.split_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    }
   ],
   "source": [
    "###First learn model on clients:\n",
    "round_weights = []\n",
    "dataset_size = 0\n",
    "applicable_models = []\n",
    "first = True\n",
    "\n",
    "for client in clients:\n",
    "    client.init_empty_model(selected_model,0.01)\n",
    "    \n",
    "    X_train = client.x_chunks[0]\n",
    "    y_train = client.y_chunks[0]\n",
    "\n",
    "    client.round_number = 1\n",
    "\n",
    "    client.train_model(X_train,y_train)\n",
    "    dataset_size += client.x.shape[0]\n",
    "    round_weights.append(client.x.shape[0])\n",
    "    applicable_models.append(client.model)\n",
    "    if first:\n",
    "        fedavg.model = client.model\n",
    "        first = False\n",
    "    print('.')\n",
    "\n",
    "round_weights = np.array(round_weights) / dataset_size # calculate weight based on actual dataset size\n",
    "fedavg.update_global_model(applicable_models, round_weights, selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45586513697026454\n"
     ]
    }
   ],
   "source": [
    "y_hat = fedavg.model.predict(test_x)\n",
    "score = f1_score(test_y,y_hat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08608957113467322\n",
      "2 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "Weights sum to zero, can't be normalized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     applicable_models\u001b[39m.\u001b[39mappend(client\u001b[39m.\u001b[39mmodel)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m round_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(round_weights) \u001b[39m/\u001b[39m dataset_size \u001b[39m# calculate weight based on actual dataset size\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m fedavg\u001b[39m.\u001b[39;49mupdate_global_model(applicable_models, round_weights, selected_model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m y_hat \u001b[39m=\u001b[39m fedavg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(test_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m score \u001b[39m=\u001b[39m f1_score(test_y,y_hat)\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/fedavg.py:112\u001b[0m, in \u001b[0;36mFedavg.update_global_model\u001b[0;34m(self, applicable_models, round_weights, model_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m     coefs\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mcoefs_)\n\u001b[1;32m    111\u001b[0m     intercept\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mintercepts_)\n\u001b[0;32m--> 112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcoefs_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49maverage(\n\u001b[1;32m    113\u001b[0m     coefs, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, weights\u001b[39m=\u001b[39;49mround_weights\n\u001b[1;32m    114\u001b[0m )  \u001b[39m# weight\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mintercepts_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(\n\u001b[1;32m    116\u001b[0m     intercept, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39mround_weights\n\u001b[1;32m    117\u001b[0m )\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:409\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    407\u001b[0m     scl \u001b[39m=\u001b[39m wgt\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mresult_dtype)\n\u001b[1;32m    408\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(scl \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m):\n\u001b[0;32m--> 409\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWeights sum to zero, can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be normalized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    412\u001b[0m     avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(a, wgt, dtype\u001b[39m=\u001b[39mresult_dtype)\u001b[39m.\u001b[39msum(axis)\u001b[39m/\u001b[39mscl\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m returned:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: Weights sum to zero, can't be normalized"
     ]
    }
   ],
   "source": [
    "number_of_rounds = 9\n",
    "epochs = 200\n",
    "max_score = 0\n",
    "optimal_model = None\n",
    "\n",
    "for round in range(number_of_rounds):\n",
    "    print(round + 1, end=' ')\n",
    "\n",
    "    applicable_clients = random.sample((clients),2)# random.randint(3,3))\n",
    "    applicable_models = []\n",
    "    applicable_name = []\n",
    "    round_weights = []\n",
    "    dataset_size = 0\n",
    "\n",
    "    for client in applicable_clients:\n",
    "        # print(f'Client name: {client.name}')\n",
    "\n",
    "        # X_train, X_test, y_train, y_test = client.split_data()        \n",
    "\n",
    "        X_train = client.x_chunks[round + 1]\n",
    "        y_train = client.y_chunks[round + 1]\n",
    "\n",
    "        ##\n",
    "        ## Try to use all the data\n",
    "        ##\n",
    "        # client.round_number += 1\n",
    "\n",
    "        # if client.round_number == 10:\n",
    "        #     clients.remove(client)\n",
    "        #     print(f'client {client.name} removed.')\n",
    "       \n",
    "        dataset_size += X_train.shape[0]\n",
    "        sample_weights = compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "        fedavg.load_global_model(client.model, selected_model)\n",
    "        try:\n",
    "            fedavg.train_local_agent(X_train, y_train, client.model, epochs, sample_weights, selected_model)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        round_weights.append(X_train.shape[0])\n",
    "        applicable_models.append(client.model)\n",
    "\n",
    "\n",
    "    round_weights = np.array(round_weights) / dataset_size # calculate weight based on actual dataset size\n",
    "    try:\n",
    "        fedavg.update_global_model(applicable_models, round_weights, selected_model)\n",
    "    except ZeroDivisionError:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    y_hat = fedavg.model.predict(test_x)\n",
    "    score = f1_score(test_y,y_hat)\n",
    "    if score > max_score:\n",
    "        print(score)\n",
    "        max_score = score\n",
    "        optimal_model = deepcopy(fedavg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664110926741813\n",
      "0.6641364052487031\n"
     ]
    }
   ],
   "source": [
    "x = test_x\n",
    "y_hat = fedavg.model.predict(x)\n",
    "score = f1_score(test_y,y_hat)\n",
    "print(score)\n",
    "y_hat = optimal_model.predict(x)\n",
    "score = f1_score(test_y,y_hat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference -0.046764424611234534\n",
      "Difference -0.0487887138033799\n",
      "Difference -0.04696718692408208\n",
      "Difference -0.04825297528227046\n",
      "Difference -0.051224557570334506\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for client in clients:\n",
    "    print(f'Difference {score-f1_before[i]}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized Zone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node1.\n"
     ]
    }
   ],
   "source": [
    "client1 = Client(\"node1\",\"0.0.0.0\", 5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m client1\u001b[39m.\u001b[39mpreprocess_data(dataset, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m client1\u001b[39m.\u001b[39mdownsample_data([\u001b[39m'\u001b[39m\u001b[39mDestination Port\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFlow Duration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTotal Fwd Packets\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTotal Backward Packets\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTotal Length of Fwd Packets\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_avg_csids_data.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m client1\u001b[39m.\u001b[39;49mprep_data()\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/client.py:239\u001b[0m, in \u001b[0;36mClient.prep_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprep_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     prep \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m prep\u001b[39m.\u001b[39;49mfit_transform(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:806\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 806\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:841\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \n\u001b[1;32m    811\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    840\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 841\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    842\u001b[0m     X,\n\u001b[1;32m    843\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    844\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    845\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    846\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    847\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    848\u001b[0m )\n\u001b[1;32m    849\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    851\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:103\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# false positives from overflow in sum method. The sum is also calculated\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m# safely to reduce dtype induced overflows.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m is_float \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[39mif\u001b[39;00m is_float \u001b[39mand\u001b[39;00m (np\u001b[39m.\u001b[39misfinite(_safe_accumulator_op(np\u001b[39m.\u001b[39;49msum, X))):\n\u001b[1;32m    104\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39melif\u001b[39;00m is_float:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:895\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    896\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2259\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2257\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2259\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2260\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = client1.load_data('datasets/Wednesday-workingHours.pcap_ISCX.csv', True)\n",
    "\n",
    "client1.preprocess_data(dataset, True)\n",
    "\n",
    "client1.downsample_data(['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets','Total Length of Fwd Packets'])\n",
    "\n",
    "client1.prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = client1.x\n",
    "y = client1.y\n",
    "\n",
    "client1.x = X[:200000]\n",
    "client1.y = y[:200000]\n",
    "\n",
    "test_x = X[600000:]\n",
    "test_y = y[600000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1.init_empty_model(selected_model,0.01)\n",
    "client1.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661761376499887\n"
     ]
    }
   ],
   "source": [
    "y_hat = client1.model.predict(test_x)\n",
    "score = f1_score(test_y,y_hat, average=\"binary\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23a6e25f04d9f91b77ea4396a46e870b27d23d0696169b2210a13d1cc496850"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
