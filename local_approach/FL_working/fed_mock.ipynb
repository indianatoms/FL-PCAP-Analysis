{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('fede'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# import pandas as pd\n",
    "from client import Client\n",
    "from supported_modles import Supported_modles\n",
    "import utils\n",
    "from fedavg import Fedavg\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.NN_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node1.\n",
      "Creating node2.\n",
      "Creating node3.\n",
      "DOWNSAMLING node3\n"
     ]
    }
   ],
   "source": [
    "clients = utils.set_data_mock(selected_model, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9754584326454347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m clients:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     client\u001b[39m.\u001b[39minit_empty_model(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     client\u001b[39m.\u001b[39;49mtrain_model(epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mtry\u001b[39;00m: \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/fed_mock.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         score \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mtest_model_f1()\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/client.py:255\u001b[0m, in \u001b[0;36mClient.train_model\u001b[0;34m(self, x, y, epochs)\u001b[0m\n\u001b[1;32m    252\u001b[0m     x_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(x_train)\n\u001b[1;32m    253\u001b[0m     y_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(y_train)\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(x_train, y_train, epochs)\n\u001b[1;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/client.py:380\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, x, y, num_epochs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    379\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 380\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m    381\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(output, y)\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m#what is going on over here\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/network.py:14\u001b[0m, in \u001b[0;36mNet2nn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m     13\u001b[0m     x\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[0;32m---> 14\u001b[0m     x\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(x))\n\u001b[1;32m     15\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_before = []\n",
    "for client in clients:\n",
    "    client.init_empty_model(0.01)\n",
    "    client.train_model(epochs=50)\n",
    "    try: \n",
    "        score = client.test_model_f1()\n",
    "    except IndexError:\n",
    "        score = 0\n",
    "    f1_before.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waitiing for a Connection..\n"
     ]
    }
   ],
   "source": [
    "fedavg = Fedavg(\"global\", selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "###First learn model on clients:\n",
    "round_weights = []\n",
    "dataset_size = 0\n",
    "applicable_models = []\n",
    "first = True\n",
    "epochs = 10\n",
    "\n",
    "for client in clients:\n",
    "    client.init_empty_model(0.01)\n",
    "    X_train, X_test, y_train, y_test = client.split_data(0.8)\n",
    "\n",
    "    client.train_model(X_train,y_train,epochs=epochs)\n",
    "    dataset_size += client.x.shape[0]\n",
    "    round_weights.append(dataset_size)\n",
    "    applicable_models.append(client.model)\n",
    "    if first:\n",
    "        fedavg.init_global_model(client.model)\n",
    "        first = False\n",
    "    print('.')\n",
    "\n",
    "round_weights = np.array(round_weights) / dataset_size # calculate weight based on actual dataset size\n",
    "fedavg.update_global_model(applicable_models, round_weights, selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .[29414]\n",
      ".[29414, 31106]\n",
      ".[29414, 31106, 2570]\n",
      "0.8123869675301189\n",
      "0.6977309408525586\n",
      "0.9579288025889968\n",
      "2 .[31106]\n",
      ".[31106, 2570]\n",
      ".[31106, 2570, 29414]\n",
      "0.9367877082083698\n",
      "0.8371523333746198\n",
      "0.9223040857334226\n",
      "3 .[31106]\n",
      ".[31106, 29414]\n",
      ".[31106, 29414, 2570]\n",
      "0.9343957032289121\n",
      "0.9243940476964065\n",
      "0.9873280231716147\n",
      "4 .[29414]\n",
      ".[29414, 2570]\n",
      ".[29414, 2570, 31106]\n",
      "0.9410026543797266\n",
      "0.9395171957671957\n",
      "0.9645125140082181\n",
      "5 .[29414]\n",
      ".[29414, 31106]\n",
      ".[29414, 31106, 2570]\n",
      "0.9527524924143911\n",
      "0.9426215938814025\n",
      "0.9835043988269795\n",
      "6 .[31106]\n",
      ".[31106, 29414]\n",
      ".[31106, 29414, 2570]\n",
      "0.9760554732926433\n",
      "0.9422765518336244\n",
      "0.9874236435501258\n",
      "7 .[29414]\n",
      ".[29414, 2570]\n",
      ".[29414, 2570, 31106]\n",
      "0.9709646446845489\n",
      "0.9661750561077268\n",
      "0.9942112879884225\n",
      "8 .[2570]\n",
      ".[2570, 29414]\n",
      ".[2570, 29414, 31106]\n",
      "0.982995484676722\n",
      "0.9705598765828888\n",
      "0.9824881430134986\n",
      "9 .[2570]\n",
      ".[2570, 29414]\n",
      ".[2570, 29414, 31106]\n",
      "0.9771101227883592\n",
      "0.9715103839904766\n",
      "0.9845201238390092\n"
     ]
    }
   ],
   "source": [
    "number_of_rounds = 9\n",
    "epochs = 10\n",
    "max_score = 0\n",
    "optimal_model = None\n",
    "\n",
    "\n",
    "for round in range(number_of_rounds):\n",
    "    print(round +1, end=' ')\n",
    "\n",
    "    applicable_clients = random.sample((clients), len(clients))#random.randint(1, 4))\n",
    "    applicable_models = []\n",
    "    applicable_name = []\n",
    "    round_weights = []\n",
    "    dataset_size = 0\n",
    "    \n",
    "\n",
    "    for client in applicable_clients:\n",
    "        print(f'.', end='')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = client.split_data(0.8)\n",
    "       \n",
    "        dataset_size += X_train.shape[0]\n",
    "        sample_weights = compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "        client.load_global_model(fedavg.model)\n",
    "        client.train_local_agent(X_train, y_train, epochs, sample_weights)\n",
    "        round_weights.append(X_train.shape[0])\n",
    "        applicable_models.append(client.model)\n",
    "        print(round_weights)\n",
    "\n",
    "\n",
    "    round_weights = np.array(round_weights) / dataset_size\n",
    "    fedavg.update_global_model(applicable_models, round_weights, selected_model)\n",
    "\n",
    "    for client in clients:\n",
    "        score = fedavg.test_model_f1(y_test=client.y_test, X_test=client.x_test)\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23a6e25f04d9f91b77ea4396a46e870b27d23d0696169b2210a13d1cc496850"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
