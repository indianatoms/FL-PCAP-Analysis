{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('fede'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from global_model import GlobalModel\n",
    "import pandas as pd\n",
    "from supported_modles import Supported_modles\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.MLP_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating node1.\n",
      "Creating node2.\n",
      "Creating node3.\n",
      "Creating node4.\n",
      "Creating node5.\n"
     ]
    }
   ],
   "source": [
    "clients, test_x, test_y = utils.set_data(True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute '_label_binarizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/naive_avg.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/naive_avg.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m clients:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/naive_avg.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     client\u001b[39m.\u001b[39minit_empty_model(selected_model,\u001b[39m0.01\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tk/Desktop/Studia/masters/git-repo/local_approach/FL_working/naive_avg.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     client\u001b[39m.\u001b[39;49mpartial_train_model()\n",
      "File \u001b[0;32m~/Desktop/Studia/masters/git-repo/local_approach/FL_working/fede/client.py:237\u001b[0m, in \u001b[0;36mClient.partial_train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpartial_train_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpartial_fit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my, classes\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray([\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1206\u001b[0m, in \u001b[0;36mMLPClassifier.partial_fit\u001b[0;34m(self, X, y, classes)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1204\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_binarizer\u001b[39m.\u001b[39mfit(classes)\n\u001b[0;32m-> 1206\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n\u001b[1;32m   1208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:780\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m@available_if\u001b[39m(_check_solver)\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpartial_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    765\u001b[0m     \u001b[39m\"\"\"Update the model with a single iteration over the given data.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \n\u001b[1;32m    767\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39m        Trained MLP model.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:393\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    387\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m hidden_layer_sizes\n\u001b[1;32m    388\u001b[0m     )\n\u001b[1;32m    389\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoefs_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    390\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m incremental\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, y, incremental, reset\u001b[39m=\u001b[39;49mfirst_pass)\n\u001b[1;32m    395\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    397\u001b[0m \u001b[39m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1150\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`y` has classes not in `self.classes_`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`self.classes_` has \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m\u001b[39m has \u001b[39m\u001b[39m{\u001b[39;00mclasses\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m         )\n\u001b[1;32m   1148\u001b[0m \u001b[39m# This downcast to bool is to prevent upcasting when working with\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m \u001b[39m# float32 data\u001b[39;00m\n\u001b[0;32m-> 1150\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_label_binarizer\u001b[39m.\u001b[39mtransform(y)\u001b[39m.\u001b[39mastype(\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1151\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute '_label_binarizer'"
     ]
    }
   ],
   "source": [
    "f1_before = []\n",
    "for client in clients:\n",
    "    client.init_empty_model(selected_model,0.01)\n",
    "    client.train_model()\n",
    "    y_hat = client.model.predict(test_x)\n",
    "    f1_before.append(f1_score(test_y,y_hat, average=\"binary\"))\n",
    "    client.split_data()\n",
    "    print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9947910429888637,\n",
       " 0.9945059057770326,\n",
       " 0.9952062797734966,\n",
       " 0.9950877613370873,\n",
       " 0.9956259923904252]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = GlobalModel(selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new round!\n",
      "Initializing Global Model\n",
      "Client name: node3\n",
      "[1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956659924877203\n",
      "0.9956627700441985\n",
      "0.9950426994376171\n",
      "0.995704574836315\n",
      "f1 fede was better\n",
      "0.9960553087239963\n",
      "0.9960553087239963\n",
      "0.9961816219805761\n",
      "0.9958492445625104\n",
      "0.996120992035654\n",
      "0.995316787357389\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node1\n",
      "Client name: node4\n",
      "Client name: node5\n",
      "Client name: node3\n",
      "[0.22495733 0.22502204 0.32501443 0.22500619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956659924877203\n",
      "0.7851464224615076\n",
      "0.995704574836315\n",
      "0.7834495394167642\n",
      "0.7766792375904596\n",
      "0.7766792375904596\n",
      "0.9961816219805761\n",
      "0.7834143377885783\n",
      "0.996120992035654\n",
      "0.7837334541245157\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node5\n",
      "[1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:377: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956659924877203\n",
      "0.995910949568378\n",
      "f1 fede was better\n",
      "0.995704574836315\n",
      "0.9961628294961629\n",
      "f1 fede was better\n",
      "0.9960546534324516\n",
      "0.9960546534324516\n",
      "0.9961816219805761\n",
      "0.9961399576640518\n",
      "0.996120992035654\n",
      "0.996120992035654\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "number_of_rounds = 3\n",
    "start = True\n",
    "for _ in range(number_of_rounds):\n",
    "    RANDOM_NUMBER_OF_CLIENTS = random.randint(1,4)\n",
    "\n",
    "    print(f'Starting new round!')\n",
    "    f1s = np.empty((0,RANDOM_NUMBER_OF_CLIENTS), float)\n",
    "    data_weights = arr = np.empty((0,RANDOM_NUMBER_OF_CLIENTS), float)\n",
    "\n",
    "    applicable_clients = random.sample((clients), RANDOM_NUMBER_OF_CLIENTS)\n",
    "\n",
    "    if start:\n",
    "        print('Initializing Global Model')\n",
    "        global_model.model = applicable_clients[0].model\n",
    "        start = False\n",
    "\n",
    "    for client in applicable_clients:\n",
    "        print(f'Client name: {client.name}')\n",
    "        f1s = np.append(f1s, client.test_model_f1())\n",
    "        data_weights = np.append(data_weights, client.x.shape[0])\n",
    "        \n",
    "    round_weights = (f1s/sum(f1s) + data_weights/sum(data_weights))/2\n",
    "    print(round_weights)\n",
    "\n",
    "    global_model.update_global_model(applicable_clients,round_weights,selected_model)\n",
    "\n",
    "    for client in clients:\n",
    "        f1_fede = global_model.f1_score(client.x_test,client.y_test)\n",
    "        f1_local = client.test_model_f1()\n",
    "\n",
    "        print(f1_local)\n",
    "        print(f1_fede)\n",
    "\n",
    "        if f1_fede > f1_local:\n",
    "            print(\"f1 fede was better\")\n",
    "            client.F1 = f1_fede\n",
    "            # local was better set to local values\n",
    "            if selected_model == Supported_modles.MLP_classifier:\n",
    "                client.model.intercepts_ = global_model.model.intercepts_\n",
    "                client.model.coefs_ = global_model.model.coefs_\n",
    "            else:\n",
    "                client.model.intercept_ = global_model.model.intercept_\n",
    "                client.model.coef_ = global_model.model.coef_\n",
    "                \n",
    "    print(f'++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00083494940156148\n",
      "0.001120086613392579\n",
      "0.0004197126169285248\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for client in clients:\n",
    "    y_hat = client.model.predict(test_x)\n",
    "    print(f1_score(test_y,y_hat) - f1_before[i])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23a6e25f04d9f91b77ea4396a46e870b27d23d0696169b2210a13d1cc496850"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
