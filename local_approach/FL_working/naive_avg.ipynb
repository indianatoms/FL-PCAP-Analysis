{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import Client\n",
    "from global_model import Global_model\n",
    "from sklearn.utils import shuffle\n",
    "from supported_modles import Supported_modles\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = Supported_modles.logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NODEs\n",
    "clients = utils.set_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.723939393939394\n",
      "Model f1 score: 0.7694838056680162\n",
      "Total size: 13400\n",
      "Totla sum of malicious packets: 7439\n",
      "-------------------------------------------------\n",
      "Model accuracy: 0.7177272727272728\n",
      "Model f1 score: 0.7657487740475292\n",
      "Total size: 13400\n",
      "Totla sum of malicious packets: 7399\n",
      "-------------------------------------------------\n",
      "Model accuracy: 0.7212121212121212\n",
      "Model f1 score: 0.769307923771314\n",
      "Total size: 6700\n",
      "Totla sum of malicious packets: 3739\n",
      "-------------------------------------------------\n",
      "Model accuracy: 0.713030303030303\n",
      "Model f1 score: 0.7582333418432473\n",
      "Total size: 6700\n",
      "Totla sum of malicious packets: 3647\n",
      "-------------------------------------------------\n",
      "Model accuracy: 0.7256445047489823\n",
      "Model f1 score: 0.77367360644728\n",
      "Total size: 14962\n",
      "Totla sum of malicious packets: 8179\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f1_before = []\n",
    "for client in clients:\n",
    "    client.downsample_data(['sbytes','dbytes','sttl','dttl','spkts','dpkts'])\n",
    "    client.split_data()\n",
    "    # client.prep_data()\n",
    "    client.train_model(selected_model)\n",
    "    print(f'Model accuracy: {client.accuracy}')\n",
    "    print(f'Model f1 score: {client.F1}')\n",
    "    f1_before.append(client.F1)\n",
    "    print(f'Total size: {client.x.shape[0]}')\n",
    "    print(f'Totla sum of malicious packets: {client.y.sum()}')\n",
    "    print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = Global_model(selected_model)\n",
    "global_model.init_global_model(client1.x.shape[1], selected_model, client1.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new round!\n",
      "Client name: node3\n",
      "f1 fede was better\n",
      "f1 fede was better\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node1\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node1\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node3\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Starting new round!\n",
      "Client name: node4\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "number_of_rounds = 10\n",
    "for _ in range(number_of_rounds):\n",
    "    RANDOM_NUMBER_OF_CLIENTS = random.randint(1, 1)\n",
    "\n",
    "    print(f'Starting new round!')\n",
    "    f1s = np.empty((0,RANDOM_NUMBER_OF_CLIENTS), float)\n",
    "    data_weights = arr = np.empty((0,RANDOM_NUMBER_OF_CLIENTS), float)\n",
    "\n",
    "    applicable_clients = random.sample((clients), RANDOM_NUMBER_OF_CLIENTS)\n",
    "\n",
    "    for client in applicable_clients:\n",
    "        print(f'Client name: {client.name}')\n",
    "        client.test_model_f1()\n",
    "        f1s = np.append(f1s, client.F1)\n",
    "        data_weights = np.append(data_weights, client.x.shape[0])\n",
    "    \n",
    "    # print(f'Weights: {f1s/sum(f1s)}')\n",
    "    # print(f'weigths data: {data_weights/sum(data_weights)}')\n",
    "    \n",
    "    round_weights = (f1s/sum(f1s) + data_weights/sum(data_weights))/2\n",
    "    \n",
    "    # print(round_weights)\n",
    "\n",
    "    global_model.update_global_model(applicable_clients,round_weights,selected_model)\n",
    "\n",
    "    for client in clients:\n",
    "        f1_fede = global_model.f1_score(client.x_test,client.y_test)\n",
    "        f1_local = client.test_model_f1()\n",
    "\n",
    "        if f1_fede > f1_local:\n",
    "            print(\"f1 fede was better\")\n",
    "            client.F1 = f1_fede\n",
    "            # local was better set to local values\n",
    "            if selected_model == Supported_modles.MLP_classifier:\n",
    "                client.model.intercepts_ = global_model.model.intercepts_\n",
    "                client.model.coefs_ = global_model.model.coefs_\n",
    "            else:\n",
    "                client.model.intercept_ = global_model.model.intercept_\n",
    "                client.model.coef_ = global_model.model.coef_\n",
    "                \n",
    "    print(f'++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714213709677419\n",
      "Difference 0.0019375652997256632\n",
      "0.7657487740475292\n",
      "Difference 0.0\n",
      "0.769307923771314\n",
      "Difference 0.0\n",
      "0.7621457489878543\n",
      "Difference 0.003912407144606944\n",
      "0.77367360644728\n",
      "Difference 0.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for client in clients:\n",
    "    print(client.F1)\n",
    "    f1_before[i]\n",
    "    print(f'Difference {client.F1-f1_before[i]}')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
