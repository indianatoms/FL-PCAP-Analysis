{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5, 2.4, 3.7, 1. ],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [7.1, 3. , 5.9, 2.1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(NeuralNetworkClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim,128)\n",
    "        self.hidden_layer1  = nn.Linear(128,64)\n",
    "        self.output_layer   = nn.Linear(64,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = 4 \n",
    "output_dim = 3\n",
    "model = NeuralNetworkClassificationModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward feed\n",
    "        output_train = model(X_train)\n",
    "\n",
    "        #calculate the loss\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        \n",
    "\n",
    "\n",
    "        #backward propagation: calculate gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        output_test = model(X_test)\n",
    "        loss_test = criterion(output_test,y_test)\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        test_losses[epoch] = loss_test.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss_train.item():.4f}, Test Loss: {loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "train_losses = np.zeros(num_epochs)\n",
    "test_losses  = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Train Loss: 0.0234, Test Loss: 0.0028\n",
      "Epoch 100/1000, Train Loss: 0.0013, Test Loss: 0.0127\n",
      "Epoch 150/1000, Train Loss: 0.0003, Test Loss: 0.0678\n",
      "Epoch 200/1000, Train Loss: 0.0002, Test Loss: 0.1165\n",
      "Epoch 250/1000, Train Loss: 0.0001, Test Loss: 0.1414\n",
      "Epoch 300/1000, Train Loss: 0.0001, Test Loss: 0.1647\n",
      "Epoch 350/1000, Train Loss: 0.0001, Test Loss: 0.1783\n",
      "Epoch 400/1000, Train Loss: 0.0000, Test Loss: 0.1863\n",
      "Epoch 450/1000, Train Loss: 0.0000, Test Loss: 0.1917\n",
      "Epoch 500/1000, Train Loss: 0.0000, Test Loss: 0.1948\n",
      "Epoch 550/1000, Train Loss: 0.0000, Test Loss: 0.1983\n",
      "Epoch 600/1000, Train Loss: 0.0000, Test Loss: 0.2012\n",
      "Epoch 650/1000, Train Loss: 0.0000, Test Loss: 0.2040\n",
      "Epoch 700/1000, Train Loss: 0.0000, Test Loss: 0.2064\n",
      "Epoch 750/1000, Train Loss: 0.0000, Test Loss: 0.2081\n",
      "Epoch 800/1000, Train Loss: 0.0000, Test Loss: 0.2098\n",
      "Epoch 850/1000, Train Loss: 0.0000, Test Loss: 0.2111\n",
      "Epoch 900/1000, Train Loss: 0.0000, Test Loss: 0.2123\n",
      "Epoch 950/1000, Train Loss: 0.0000, Test Loss: 0.2134\n",
      "Epoch 1000/1000, Train Loss: 0.0000, Test Loss: 0.2143\n"
     ]
    }
   ],
   "source": [
    "train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = []\n",
    "predictions_test =  []\n",
    "with torch.no_grad():\n",
    "    predictions_train = model(X_train)\n",
    "    predictions_test = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_multiclass(pred_arr,original_arr):\n",
    "    if len(pred_arr)!=len(original_arr):\n",
    "        return False\n",
    "    pred_arr = pred_arr.numpy()\n",
    "    original_arr = original_arr.numpy()\n",
    "    final_pred= []\n",
    "    # we will get something like this in the pred_arr [32.1680,12.9350,-58.4877]\n",
    "    # so will be taking the index of that argument which has the highest value here 32.1680 which corresponds to 0th index\n",
    "    for i in range(len(pred_arr)):\n",
    "        final_pred.append(np.argmax(pred_arr[i]))\n",
    "    final_pred = np.array(final_pred)\n",
    "    count = 0\n",
    "    #here we are doing a simple comparison between the predicted_arr and the original_arr to get the final accuracy\n",
    "    for i in range(len(original_arr)):\n",
    "        if final_pred[i] == original_arr[i]:\n",
    "            count+=1\n",
    "    return count/len(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = get_accuracy_multiclass(predictions_train,y_train)\n",
    "test_acc  = get_accuracy_multiclass(predictions_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0\n",
      "Test Accuracy: 97.778\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {round(train_acc*100,3)}\")\n",
    "print(f\"Test Accuracy: {round(test_acc*100,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_layer.weight',\n",
       "              tensor([[-0.2385, -0.2079, -0.1759, -0.4506],\n",
       "                      [ 0.2981,  0.0501,  0.5146,  0.0825],\n",
       "                      [ 0.8148, -0.0511, -0.7532, -0.0883],\n",
       "                      [ 0.2106, -0.2268, -0.0886,  0.1794],\n",
       "                      [ 0.1929, -0.3958, -0.5818, -0.5186],\n",
       "                      [ 0.4223, -0.3124, -0.4365,  0.5737],\n",
       "                      [ 0.4077, -0.4353, -0.0733, -0.2410],\n",
       "                      [ 0.5840,  0.9667, -0.2527, -0.4165],\n",
       "                      [ 0.5015,  0.7366, -0.1415, -0.1055],\n",
       "                      [ 0.2424,  0.1195, -0.1461, -0.3341],\n",
       "                      [-0.4271,  0.0694, -0.3341, -0.2186],\n",
       "                      [ 0.3556, -0.4833,  0.3046,  0.0412],\n",
       "                      [ 0.1849,  0.0668, -0.1074, -0.1607],\n",
       "                      [-0.1345,  0.1405,  0.0858,  0.4678],\n",
       "                      [-0.2162,  0.3792, -0.0507,  0.1469],\n",
       "                      [ 0.2096, -0.1872, -0.7681,  0.1230],\n",
       "                      [ 0.4009, -0.1127, -0.2332,  0.4038],\n",
       "                      [ 0.0208,  0.3099,  0.1467,  0.3768],\n",
       "                      [ 0.4814,  0.0730,  0.3296,  0.3623],\n",
       "                      [ 0.1703, -0.2510,  0.6364,  0.5121],\n",
       "                      [-0.1804, -0.3412,  0.3994, -0.3805],\n",
       "                      [ 0.1856, -0.1620,  0.5205, -0.1390],\n",
       "                      [ 0.0200, -0.1929, -0.0980,  0.3802],\n",
       "                      [-0.1190, -0.2542, -0.6354, -0.1351],\n",
       "                      [ 0.0082,  0.1773,  0.3430,  0.3802],\n",
       "                      [ 0.6227,  0.5328,  0.2223,  0.4044],\n",
       "                      [ 0.2987, -0.1088, -0.4882,  0.5441],\n",
       "                      [-0.4574, -0.4196, -0.3727,  0.5855],\n",
       "                      [-0.2112, -0.1191,  0.6954, -0.0115],\n",
       "                      [-0.1511,  0.0425, -0.1846, -0.6685],\n",
       "                      [-0.1986, -0.1545, -0.2675,  0.2100],\n",
       "                      [ 0.1042, -0.1701, -0.0929,  0.1863],\n",
       "                      [-0.3917,  0.2658, -0.3124, -0.3332],\n",
       "                      [-0.1340, -0.2369, -0.5758,  0.9784],\n",
       "                      [ 0.2003,  0.0209, -0.4738,  0.5465],\n",
       "                      [ 0.2208, -0.0863,  0.6936,  0.2341],\n",
       "                      [-0.9857,  0.0394,  0.1163, -0.1475],\n",
       "                      [ 0.5842, -0.3083,  0.3532, -0.4194],\n",
       "                      [ 0.4352, -0.4153,  0.6824, -0.0201],\n",
       "                      [-0.0692, -0.3538, -0.3405, -0.6087],\n",
       "                      [ 0.3251,  0.0957,  0.2519,  0.4169],\n",
       "                      [-0.5284,  0.6691, -0.1389,  0.1153],\n",
       "                      [ 0.0581,  0.0918, -0.3736, -0.5713],\n",
       "                      [-0.5448, -0.6314, -0.2703, -0.1084],\n",
       "                      [-0.1099, -0.3380, -0.5606, -0.0081],\n",
       "                      [ 0.3017, -0.1853,  0.2435,  0.2911],\n",
       "                      [-0.1877, -0.1814,  0.6822, -0.0213],\n",
       "                      [-0.2913,  0.1350, -0.5232,  0.8731],\n",
       "                      [ 0.1951, -0.2252,  0.0473,  0.2142],\n",
       "                      [-0.0499,  0.2622,  0.2134, -0.2676],\n",
       "                      [ 0.2284,  0.4794,  0.7267,  0.2461],\n",
       "                      [-0.1687, -0.0678,  0.3770,  0.2233],\n",
       "                      [ 0.0338,  0.0908, -0.4283,  0.3317],\n",
       "                      [-0.7620, -0.6428,  0.2197, -0.5721],\n",
       "                      [ 0.1203,  0.1854,  0.3622,  0.1828],\n",
       "                      [ 0.3795, -0.3699,  0.2154,  0.1289],\n",
       "                      [ 0.2051,  0.1333, -0.1666, -0.1269],\n",
       "                      [-0.3570,  0.8670, -0.5747, -0.1123],\n",
       "                      [-0.0864, -0.5688, -0.4228,  0.7270],\n",
       "                      [ 0.6595,  0.4902, -0.3844,  0.4696],\n",
       "                      [-0.3673,  0.3345,  0.2702,  0.0092],\n",
       "                      [-0.6712, -0.5675, -0.2791, -0.3620],\n",
       "                      [-0.4562, -0.1500, -0.1757,  0.9265],\n",
       "                      [-0.7108, -0.3767, -0.2390, -0.3495],\n",
       "                      [-0.5056,  0.5589, -0.2342, -0.3002],\n",
       "                      [-0.3944,  0.4787,  0.0986, -0.1452],\n",
       "                      [-0.3896,  0.1953, -0.0782, -0.6170],\n",
       "                      [-0.5923,  0.0748, -0.5689, -0.4493],\n",
       "                      [ 0.5009,  0.0798,  0.2794, -0.4996],\n",
       "                      [ 0.2233, -0.0722, -0.2932, -0.4642],\n",
       "                      [ 0.6122,  0.8731,  0.2038, -0.2988],\n",
       "                      [ 0.1037, -0.1676, -0.2540,  0.6582],\n",
       "                      [ 0.0271, -0.0627, -0.1544, -0.1936],\n",
       "                      [ 0.2740,  0.2275,  0.3858,  0.1177],\n",
       "                      [ 0.1682, -0.4002,  0.5742,  0.2741],\n",
       "                      [-0.4573,  0.2003, -0.6092, -0.3710],\n",
       "                      [ 0.3941,  0.7847, -0.4449, -0.5293],\n",
       "                      [ 0.2478, -0.2920, -0.4647,  0.0901],\n",
       "                      [-0.1094,  0.0264, -0.0101,  0.2305],\n",
       "                      [ 0.0080,  0.1596,  0.7290,  0.5367],\n",
       "                      [ 0.8840, -0.0610, -0.6535, -0.0306],\n",
       "                      [ 0.3415, -0.2417,  0.3350, -0.2380],\n",
       "                      [-0.7739,  0.3174,  0.3145,  0.2865],\n",
       "                      [ 0.7421,  0.5881, -0.4164, -0.0733],\n",
       "                      [-0.0033,  0.0744,  0.5843,  0.3507],\n",
       "                      [ 0.4206, -0.4293,  0.2367,  0.1667],\n",
       "                      [-0.7974, -0.5136,  0.1906, -0.4755],\n",
       "                      [-0.0299,  0.6064, -0.0078,  0.1408],\n",
       "                      [ 0.4563,  0.1578,  0.0180,  0.1619],\n",
       "                      [-0.3886,  0.1796, -0.5335, -0.0860],\n",
       "                      [ 0.2373, -0.0858,  0.3154,  0.4907],\n",
       "                      [-0.7512,  1.2759,  0.4013, -0.0047],\n",
       "                      [-0.2808,  0.1069, -0.1705,  1.1099],\n",
       "                      [-0.3744, -0.3484, -0.4247, -0.4687],\n",
       "                      [ 0.7293,  0.3429,  0.5278,  0.3798],\n",
       "                      [-0.2721, -0.1515,  0.2933,  0.4554],\n",
       "                      [-1.1399, -0.3254,  0.1001, -0.1111],\n",
       "                      [ 0.1160, -0.3300,  0.2737,  0.6265],\n",
       "                      [ 0.3926, -0.1612,  0.6435, -1.3143],\n",
       "                      [-0.1864, -0.4137,  0.0601,  0.5079],\n",
       "                      [-0.1319,  0.2754, -0.2686,  0.0649],\n",
       "                      [-0.0941,  0.0164,  0.3592,  0.4679],\n",
       "                      [-0.0028, -0.0432,  0.3079,  0.5992],\n",
       "                      [ 0.2254,  0.4567,  0.3010,  0.4591],\n",
       "                      [ 0.1719,  0.0329,  0.3011,  0.2681],\n",
       "                      [ 0.3201,  0.2472, -0.3470,  0.3805],\n",
       "                      [ 0.5328,  0.5596,  0.8730,  0.1626],\n",
       "                      [-0.5623, -0.5290,  0.3227,  0.0809],\n",
       "                      [-0.6092, -0.0157, -0.5944, -0.5910],\n",
       "                      [-0.3019,  0.3523, -0.2903, -0.2994],\n",
       "                      [ 0.3992,  0.5590,  0.2229,  0.5661],\n",
       "                      [ 0.5369,  0.0405,  0.6015,  0.3326],\n",
       "                      [-0.0020, -0.3420, -0.4492, -0.1076],\n",
       "                      [ 0.4168, -0.4579,  0.0753, -0.5710],\n",
       "                      [-0.4473,  0.5806,  0.1346, -0.4636],\n",
       "                      [ 0.0469,  0.3066, -0.3824,  0.1948],\n",
       "                      [-0.0769, -0.1627, -0.5692,  0.2482],\n",
       "                      [ 0.2015,  0.2556,  0.5906,  0.1793],\n",
       "                      [-0.4233,  0.8015, -0.0655, -0.4643],\n",
       "                      [ 0.3938, -0.4219,  0.5880,  0.2113],\n",
       "                      [ 0.6067,  0.2648, -0.6910, -0.1343],\n",
       "                      [ 0.2494,  0.9318, -0.0743, -0.5293],\n",
       "                      [ 0.1095, -0.2808, -0.2133,  0.3797],\n",
       "                      [ 0.1189, -0.2929,  0.2924, -0.3764],\n",
       "                      [-0.5827,  0.0460,  0.3403,  0.2955],\n",
       "                      [ 0.0201,  0.5378, -0.4950, -0.5738],\n",
       "                      [ 0.0875, -0.5118,  0.2757,  0.3650],\n",
       "                      [-0.9406, -0.5653, -0.3306, -0.3130]])),\n",
       "             ('input_layer.bias',\n",
       "              tensor([ 0.1378, -0.2470,  0.0969,  0.4752, -0.2386,  0.6893,  0.1914,  0.4920,\n",
       "                       0.2051, -0.4486, -0.3453,  0.1197,  0.6802, -0.1603, -0.4175,  0.5511,\n",
       "                       0.4819, -0.5086,  0.1815, -0.2667,  0.3544,  0.6461,  0.2104, -0.1537,\n",
       "                       0.4966, -0.0794,  0.7116, -0.2434,  0.2520,  0.2751,  0.5722, -0.4533,\n",
       "                       0.0568, -0.2150,  0.4350,  0.0672,  0.5317,  0.2400,  0.4861,  0.0253,\n",
       "                       0.0177,  0.1032,  0.0797, -0.2706, -0.5106,  0.5812,  0.0413,  0.1046,\n",
       "                       0.5121, -0.1947, -0.0636,  0.4525, -0.5486, -0.2114, -0.4730,  0.2155,\n",
       "                      -0.5325,  0.4845, -0.4574, -0.1997,  0.2820,  0.4300, -0.3513,  0.5210,\n",
       "                       0.0010,  0.1424,  0.2011, -0.0863,  0.1566,  0.2123,  0.0603,  0.1079,\n",
       "                       0.4029, -0.1464, -0.2826,  0.1354,  0.6833, -0.1218, -0.3836,  0.2706,\n",
       "                      -0.0380,  0.5531,  0.2592,  0.2111, -0.0116,  0.0206, -0.1349,  0.2093,\n",
       "                      -0.5809,  0.0585,  0.2539, -0.0429, -0.2871, -0.3751, -0.4342,  0.4450,\n",
       "                       0.4323,  0.5207, -0.0140, -0.1541, -0.0985, -0.0045, -0.1587, -0.1438,\n",
       "                       0.4409, -0.3766, -0.1918, -0.5576, -0.2614,  0.1413, -0.0970, -0.4366,\n",
       "                       0.7267,  0.3030,  0.3768, -0.3879,  0.6419,  0.1915,  0.4864,  0.5894,\n",
       "                       0.3420,  0.5524,  0.1409,  0.7014,  0.2768, -0.1952, -0.1785,  0.5821])),\n",
       "             ('hidden_layer1.weight',\n",
       "              tensor([[-0.0478,  0.2054, -0.3324,  ..., -0.1336,  0.2529, -0.0435],\n",
       "                      [ 0.0587,  0.2301, -0.3807,  ..., -0.1090,  0.1832, -0.1610],\n",
       "                      [ 0.1049, -0.0805,  0.0768,  ..., -0.0271, -0.0960,  0.1168],\n",
       "                      ...,\n",
       "                      [-0.0098, -0.1931,  0.2940,  ...,  0.1518, -0.1165,  0.2464],\n",
       "                      [ 0.0161,  0.2415, -0.3118,  ..., -0.0023,  0.2389, -0.1531],\n",
       "                      [-0.0480,  0.0675, -0.0251,  ..., -0.0267, -0.0876,  0.0125]])),\n",
       "             ('hidden_layer1.bias',\n",
       "              tensor([ 0.1004,  0.1173,  0.0163,  0.1838,  0.2296,  0.1678,  0.1197,  0.0900,\n",
       "                       0.0270, -0.1151, -0.1060,  0.1023, -0.0752,  0.0507, -0.0084,  0.1672,\n",
       "                       0.0296, -0.0253, -0.0966, -0.0439, -0.0350,  0.1746, -0.0007,  0.0082,\n",
       "                      -0.1271,  0.2359,  0.1675,  0.1339,  0.1016,  0.0443, -0.0243,  0.1502,\n",
       "                       0.2728,  0.1025, -0.1552,  0.1791, -0.1775,  0.2053,  0.1085,  0.2409,\n",
       "                      -0.2694, -0.1371, -0.1338, -0.0981,  0.0998,  0.0014,  0.1298, -0.1102,\n",
       "                       0.0022, -0.0195, -0.0138, -0.0733, -0.0735,  0.1531,  0.1927,  0.1854,\n",
       "                       0.2456,  0.1175,  0.0703,  0.2469,  0.2464,  0.1494, -0.1380,  0.0778])),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-0.1911, -0.1616, -0.0680,  0.0267, -0.0903,  0.2108,  0.1906, -0.1241,\n",
       "                       -0.0397,  0.0770, -0.2242, -0.2119,  0.1122,  0.2232,  0.0801, -0.2315,\n",
       "                        0.1920,  0.1373, -0.1157,  0.0878,  0.1782, -0.1563,  0.1170,  0.1884,\n",
       "                        0.0086, -0.2156, -0.2470, -0.1625,  0.2262,  0.2204,  0.0837, -0.0330,\n",
       "                       -0.1609,  0.2029, -0.1288, -0.1165, -0.0494, -0.0853,  0.2251,  0.2428,\n",
       "                       -0.0584, -0.1383,  0.0371,  0.0241, -0.1911, -0.2072,  0.2313, -0.0207,\n",
       "                        0.0305,  0.1101, -0.2346,  0.8698, -0.0266, -0.1538, -0.2295, -0.1721,\n",
       "                        0.2234,  0.2029,  0.2408, -0.2539, -0.1593,  0.1860,  0.0413,  0.0913],\n",
       "                      [-0.1311, -0.0125,  0.1075,  0.3712,  0.3332,  0.0926,  0.3329, -0.0154,\n",
       "                        0.0590, -0.0336, -0.2960, -0.1049, -0.2285, -0.0965, -0.1836,  0.0102,\n",
       "                       -0.1251, -0.2260, -0.1886, -0.0017, -0.2320,  0.5815, -0.0532, -0.2076,\n",
       "                        0.0776,  0.3433, -0.0702,  0.3454, -0.0088, -0.2373, -0.1235,  0.3526,\n",
       "                        0.2939, -0.1273, -0.2174,  0.3393, -0.4945,  0.1212, -0.0878,  0.4674,\n",
       "                       -0.3619, -0.2610, -0.0143, -0.0794,  0.2035, -0.3157, -0.1827, -0.2341,\n",
       "                        0.1168, -0.0455, -0.1399, -0.3038,  0.0402,  0.3505,  0.2261,  0.2984,\n",
       "                        0.2947, -0.1537, -0.0891,  0.2866,  0.2937,  0.2675, -0.2417,  0.0529],\n",
       "                      [ 0.1238,  0.2882,  0.0637, -0.4104, -0.5269, -0.1059, -0.4205,  0.3555,\n",
       "                        0.0449, -0.0100,  0.3265,  0.2784, -0.0756, -0.1044, -0.0894,  0.0639,\n",
       "                       -0.0068, -0.1532,  0.3845, -0.0749, -0.1645, -0.4984,  0.0685, -0.1314,\n",
       "                        0.0521, -0.3203,  0.1283, -0.4429, -0.2457, -0.1803,  0.0277, -0.2433,\n",
       "                       -0.0896, -0.0896,  0.2492, -0.1322,  0.4308,  0.1854, -0.0421, -0.4045,\n",
       "                        0.2649,  0.2725, -0.0487, -0.1084, -0.0539,  0.3562, -0.1626,  0.2111,\n",
       "                       -0.0709, -0.1104,  0.1234, -0.3235,  0.0283, -0.3096, -0.0777, -0.1272,\n",
       "                       -0.4454, -0.1091, -0.1292, -0.3028, -0.2652, -0.5695,  0.3586, -0.0267]])),\n",
       "             ('output_layer.bias', tensor([-0.1122,  0.1533, -0.1207]))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
