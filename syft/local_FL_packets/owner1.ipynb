{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from syft.core.adp.entity import Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\"\"\"Load unsw dataset\"\"\"\n",
    "unsw = pd.read_csv(\"../UNSW_NB15_training-set.csv\")\n",
    "y = unsw.iloc[:,-1:]\n",
    "#one-hot-encode parameters\n",
    "proto = pd.get_dummies(unsw['proto'])\n",
    "state = pd.get_dummies(unsw['state'])\n",
    "service = pd.get_dummies(unsw['service'])\n",
    "service = service.iloc[:,1:]\n",
    "raw_data = unsw.values\n",
    "\n",
    "#remove encoded parameters and add one hot\n",
    "for x in ['proto', 'state', 'service','label','attack_cat']:\n",
    "    unsw = unsw.drop(x,axis = 1)\n",
    "    \n",
    "for x in [proto, state, service]:\n",
    "    unsw = unsw.join(x)\n",
    "    \n",
    "X = unsw.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to None... done! \t Logging into tomek... done!\n"
     ]
    }
   ],
   "source": [
    "ds_domain = sy.login(\n",
    "    email = \"ttomek.koziak@gmail.com\",\n",
    "    password = \"1234567890\",\n",
    "    port = 8081\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data is of type: <class 'pandas.core.frame.DataFrame'>\n",
      "raw_data is of type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert a Pandas Dataframe to NumPy array\n",
    "print(f'raw_data is of type: {type(X)}')\n",
    "raw_data = X.values\n",
    "print(f'raw_data is of type: {type(raw_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "entities = []\n",
    "for i in range(raw_data.shape[0]):\n",
    "    packet_name = f\"Packet {i}\"\n",
    "    \n",
    "    # Create a new Entity correspoinding to the country and add it to the list\n",
    "    new_entity = Entity(name=packet_name)\n",
    "    entities.append(new_entity)\n",
    "    \n",
    "    # Add it to the Dataset Dictionary\n",
    "    dataset[packet_name] = sy.Tensor(raw_data[i, :].astype(np.int32)).private(min_val=0, max_val=4280658180, entities=new_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... checking asset types...                                                                                                                                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds_domain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43massets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPackets first 1000 rows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX for packets classification task\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/node/domain/client.py:686\u001b[0m, in \u001b[0;36mDomainClient.load_dataset\u001b[0;34m(self, assets, name, description, skip_checks, **metadata)\u001b[0m\n\u001b[1;32m    683\u001b[0m assets \u001b[39m=\u001b[39m downcast(assets)\n\u001b[1;32m    684\u001b[0m metadata \u001b[39m=\u001b[39m downcast(metadata)\n\u001b[0;32m--> 686\u001b[0m binary_dataset \u001b[39m=\u001b[39m serialize(assets, to_bytes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    688\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39mLoading dataset... uploading...                        \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mcreate_syft(\n\u001b[1;32m    690\u001b[0m     dataset\u001b[39m=\u001b[39mbinary_dataset, metadata\u001b[39m=\u001b[39mmetadata, platform\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msyft\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:75\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#     Exception(\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m to_bytes:\n\u001b[1;32m     72\u001b[0m     \u001b[39m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     serialized_data \u001b[39m=\u001b[39m is_serializable\u001b[39m.\u001b[39;49m_object2proto()\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m     76\u001b[0m     blob: Message \u001b[39m=\u001b[39m DataMessage(\n\u001b[1;32m     77\u001b[0m         obj_type\u001b[39m=\u001b[39mget_fully_qualified_name(obj\u001b[39m=\u001b[39mis_serializable),\n\u001b[1;32m     78\u001b[0m         content\u001b[39m=\u001b[39mserialized_data,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m validate_type(blob\u001b[39m.\u001b[39mSerializeToString(), \u001b[39mbytes\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/python/dict.py:217\u001b[0m, in \u001b[0;36mDict._object2proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m id_ \u001b[39m=\u001b[39m sy\u001b[39m.\u001b[39mserialize(obj\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid)\n\u001b[1;32m    212\u001b[0m keys \u001b[39m=\u001b[39m [\n\u001b[1;32m    213\u001b[0m     sy\u001b[39m.\u001b[39mserialize(obj\u001b[39m=\u001b[39mdowncast(value\u001b[39m=\u001b[39melement), to_bytes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m    215\u001b[0m ]\n\u001b[0;32m--> 217\u001b[0m values \u001b[39m=\u001b[39m [\n\u001b[1;32m    218\u001b[0m     sy\u001b[39m.\u001b[39mserialize(obj\u001b[39m=\u001b[39mdowncast(value\u001b[39m=\u001b[39melement), to_bytes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    220\u001b[0m ]\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtemporary_box\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    223\u001b[0m     temporary_box \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemporary_box\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/python/dict.py:218\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m id_ \u001b[39m=\u001b[39m sy\u001b[39m.\u001b[39mserialize(obj\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid)\n\u001b[1;32m    212\u001b[0m keys \u001b[39m=\u001b[39m [\n\u001b[1;32m    213\u001b[0m     sy\u001b[39m.\u001b[39mserialize(obj\u001b[39m=\u001b[39mdowncast(value\u001b[39m=\u001b[39melement), to_bytes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m    215\u001b[0m ]\n\u001b[1;32m    217\u001b[0m values \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 218\u001b[0m     sy\u001b[39m.\u001b[39;49mserialize(obj\u001b[39m=\u001b[39;49mdowncast(value\u001b[39m=\u001b[39;49melement), to_bytes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    220\u001b[0m ]\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtemporary_box\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    223\u001b[0m     temporary_box \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemporary_box\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:75\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#     Exception(\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m to_bytes:\n\u001b[1;32m     72\u001b[0m     \u001b[39m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     serialized_data \u001b[39m=\u001b[39m is_serializable\u001b[39m.\u001b[39;49m_object2proto()\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m     76\u001b[0m     blob: Message \u001b[39m=\u001b[39m DataMessage(\n\u001b[1;32m     77\u001b[0m         obj_type\u001b[39m=\u001b[39mget_fully_qualified_name(obj\u001b[39m=\u001b[39mis_serializable),\n\u001b[1;32m     78\u001b[0m         content\u001b[39m=\u001b[39mserialized_data,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m validate_type(blob\u001b[39m.\u001b[39mSerializeToString(), \u001b[39mbytes\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/recursive.py:35\u001b[0m, in \u001b[0;36mrs_object2proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m             field_obj \u001b[39m=\u001b[39m transforms[\u001b[39m0\u001b[39m](\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr_name))\n\u001b[0;32m---> 35\u001b[0m         msg\u001b[39m.\u001b[39mfields_data\u001b[39m.\u001b[39mappend(sy\u001b[39m.\u001b[39;49mserialize(field_obj, to_bytes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m msg\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:75\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#     Exception(\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m to_bytes:\n\u001b[1;32m     72\u001b[0m     \u001b[39m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     serialized_data \u001b[39m=\u001b[39m is_serializable\u001b[39m.\u001b[39;49m_object2proto()\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m     76\u001b[0m     blob: Message \u001b[39m=\u001b[39m DataMessage(\n\u001b[1;32m     77\u001b[0m         obj_type\u001b[39m=\u001b[39mget_fully_qualified_name(obj\u001b[39m=\u001b[39mis_serializable),\n\u001b[1;32m     78\u001b[0m         content\u001b[39m=\u001b[39mserialized_data,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m validate_type(blob\u001b[39m.\u001b[39mSerializeToString(), \u001b[39mbytes\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/recursive.py:35\u001b[0m, in \u001b[0;36mrs_object2proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m             field_obj \u001b[39m=\u001b[39m transforms[\u001b[39m0\u001b[39m](\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr_name))\n\u001b[0;32m---> 35\u001b[0m         msg\u001b[39m.\u001b[39mfields_data\u001b[39m.\u001b[39mappend(sy\u001b[39m.\u001b[39;49mserialize(field_obj, to_bytes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m msg\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:75\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#     Exception(\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m to_bytes:\n\u001b[1;32m     72\u001b[0m     \u001b[39m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     serialized_data \u001b[39m=\u001b[39m is_serializable\u001b[39m.\u001b[39;49m_object2proto()\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m     76\u001b[0m     blob: Message \u001b[39m=\u001b[39m DataMessage(\n\u001b[1;32m     77\u001b[0m         obj_type\u001b[39m=\u001b[39mget_fully_qualified_name(obj\u001b[39m=\u001b[39mis_serializable),\n\u001b[1;32m     78\u001b[0m         content\u001b[39m=\u001b[39mserialized_data,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m validate_type(blob\u001b[39m.\u001b[39mSerializeToString(), \u001b[39mbytes\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serializable.py:33\u001b[0m, in \u001b[0;36mGenerateWrapper.<locals>.Wrapper._object2proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_object2proto\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m type_object2proto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/numpy/array.py:89\u001b[0m, in \u001b[0;36mserialize_numpy_array\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m NumpyProto(arrow_data\u001b[39m=\u001b[39marrow_serialize(obj))\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m protobuf_serialize(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/numpy/array.py:71\u001b[0m, in \u001b[0;36mprotobuf_serialize\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m# Cloning seems to cause the worker to freeze if the array is larger than around\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# 800k in data and since we are serializing it immediately afterwards I don't\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m# think its needed anyway\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m# tensor = torch.from_numpy(obj).clone()\u001b[39;00m\n\u001b[1;32m     70\u001b[0m tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(obj)\n\u001b[0;32m---> 71\u001b[0m tensor_bytes \u001b[39m=\u001b[39m tensor_serializer(tensor)\n\u001b[1;32m     72\u001b[0m dtype \u001b[39m=\u001b[39m original_dtype\u001b[39m.\u001b[39mname\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m NumpyProto(proto_data\u001b[39m=\u001b[39mtensor_bytes, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/torch/tensor_util.py:74\u001b[0m, in \u001b[0;36mtensor_serializer\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     72\u001b[0m     protobuf_tensor\u001b[39m.\u001b[39marrow_data \u001b[39m=\u001b[39m arrow_data_encoding(tensor)\n\u001b[1;32m     73\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     protobuf_tensor\u001b[39m.\u001b[39mproto_data \u001b[39m=\u001b[39m protobuf_data_encoding(tensor)\n\u001b[1;32m     76\u001b[0m protobuf_tensor\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m TORCH_DTYPE_STR[tensor\u001b[39m.\u001b[39mdtype]\n\u001b[1;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m protobuf_tensor\u001b[39m.\u001b[39mSerializeToString()\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/lib/torch/tensor_util.py:38\u001b[0m, in \u001b[0;36mprotobuf_data_encoding\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     36\u001b[0m     data \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mflatten(tensor)\u001b[39m.\u001b[39mint_repr()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     data \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mflatten(tensor)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     40\u001b[0m dtype \u001b[39m=\u001b[39m TORCH_DTYPE_STR[tensor\u001b[39m.\u001b[39mdtype]\n\u001b[1;32m     41\u001b[0m protobuf_tensor_data\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mextend(tensor\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_domain.load_dataset(\n",
    "    assets=dataset, \n",
    "    name=\"Packets first 1000 rows\", \n",
    "    description=\"X for packets classification task\", \n",
    "    metadata=\"iot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "                #myInput {\n",
       "                  background-position: 10px 12px; /* Position the search icon */\n",
       "                  background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "                  background-color: #bbb;\n",
       "                  width: 98%; /* Full-width */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                  padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  margin-bottom: 12px; /* Add some space below the input */\n",
       "                }\n",
       "\n",
       "                #myTable {\n",
       "                  border-collapse: collapse; /* Collapse borders */\n",
       "                  width: 100%; /* Full-width */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                }\n",
       "\n",
       "                #myTable th, #myTable td {\n",
       "                  text-align: left; /* Left-align text */\n",
       "                  padding: 10px; /* Add padding */\n",
       "                }\n",
       "\n",
       "                #myTable tr {\n",
       "                  /* Add a bottom border to all table rows */\n",
       "                  border-bottom: 1px solid #ddd;\n",
       "                }\n",
       "\n",
       "                #myTable tr.header, #myTable tr:hover {\n",
       "                  /* Add a grey background color to the table header and on hover */\n",
       "                  background-color: #777;\n",
       "                }\n",
       "                </style>\n",
       "\n",
       "                <table id=\"myTable\" style=\"width:1000px\">\n",
       "                  <tr class=\"header\">\n",
       "                    <th style=\"width:30px\">Idx</th>\n",
       "                    <th style=\"width:20%;\">Name</th>\n",
       "                    <th style=\"width:35%;\">Description</th>\n",
       "                    <th style=\"width:20%;\">Assets</th>\n",
       "                    <th style=\"width:300px;\">Id</th>\n",
       "                  </tr>\n",
       "                \n",
       "\n",
       "          <tr>\n",
       "            <td>[0]</td>\n",
       "            <td>Packets first 40000 rows</td>\n",
       "            <td>X for packets classification task</td>\n",
       "            <td>[\"Packet 0\"] -> Tensor<br /><br />[\"Packet 1\"] -> Tensor<br /><br />[\"Packet 2\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>2b7581cd-9cc9-4fd7-9a2d-e1b5d1d66e21</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[1]</td>\n",
       "            <td>Packets first 1000 rows</td>\n",
       "            <td>X for packets classification task</td>\n",
       "            <td>[\"Packet 0\"] -> Tensor<br /><br />[\"Packet 1\"] -> Tensor<br /><br />[\"Packet 2\"] -> Tensor<br /><br />...<br /><br /></td>\n",
       "            <td>354b7a28-8af3-441c-a656-50a122c29d48</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        <script>\n",
       "        function myFunction() {\n",
       "          // Declare variables\n",
       "          var input, filter, table, tr, td, i, txtValue;\n",
       "          input = document.getElementById(\"myInput\");\n",
       "          filter = input.value.toUpperCase();\n",
       "          table = document.getElementById(\"myTable\");\n",
       "          tr = table.getElementsByTagName(\"tr\");\n",
       "\n",
       "          // Loop through all table rows, and hide those who don't match the search query\n",
       "          for (i = 0; i < tr.length; i++) {\n",
       "            name_td = tr[i].getElementsByTagName(\"td\")[1];\n",
       "            desc_td = tr[i].getElementsByTagName(\"td\")[2];\n",
       "            asset_td = tr[i].getElementsByTagName(\"td\")[3];\n",
       "            id_td = tr[i].getElementsByTagName(\"td\")[4];\n",
       "            if (name_td || desc_td || asset_td || id_td) {\n",
       "              name_txtValue = name_td.textContent || name_td.innerText;\n",
       "              desc_txtValue = desc_td.textContent || name_td.innerText;\n",
       "              asset_txtValue = asset_td.textContent || name_td.innerText;\n",
       "              id_txtValue = id_td.textContent || name_td.innerText;\n",
       "              name_bool = name_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              desc_bool = desc_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              asset_bool = asset_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              id_bool = id_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              if (name_bool || desc_bool || asset_bool || id_bool) {\n",
       "                tr[i].style.display = \"\";\n",
       "              } else {\n",
       "                tr[i].style.display = \"none\";\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.DatasetRequestAPI at 0x7efc1686dee0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_domain.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_domain.datasets[0].delete(name=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_domain.datasets.delete(dataset_id=\"2b7581cd-9cc9-4fd7-9a2d-e1b5d1d66e21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data is of type: <class 'pandas.core.frame.DataFrame'>\n",
      "raw_data is of type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert a Pandas Dataframe to NumPy array\n",
    "print(f'raw_data is of type: {type(y)}')\n",
    "raw_data = y.values\n",
    "print(f'raw_data is of type: {type(raw_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = dict()\n",
    "entities = []\n",
    "for i in range(raw_data.shape[0]):\n",
    "    packet_name = f\"Packet {i}\"\n",
    "    \n",
    "    # Create a new Entity correspoinding to the country and add it to the list\n",
    "    new_entity = Entity(name=packet_name)\n",
    "    entities.append(new_entity)\n",
    "    \n",
    "    # Add it to the Dataset Dictionary\n",
    "    y_dataset[packet_name] = sy.Tensor(raw_data[i].astype(np.int32)).private(min_val=0, max_val=1, entities=new_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... uploading... SUCCESS!                                                                                                                                      \n",
      "\n",
      "Run <your client variable>.datasets to see your new dataset loaded into your machine!\n"
     ]
    }
   ],
   "source": [
    "ds_domain.load_dataset(\n",
    "    assets=y_dataset, \n",
    "    name=\"y Packets first 1000 rows\", \n",
    "    description=\"y for packets classification task\", \n",
    "    metadata=\"iot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_domain.requests.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('syft_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf1e7ca5fe834974bbe5ce531922913687deaa189a9e4e98f981bcccaee449a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
